{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a32a999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nVida modified the existing emission_maps code in the emission repository of foggie to dynamically get:\\n1. filters: tempreture, density, inflow,outflow, disk, cgm\\n2. resolution for frb maps\\n3. units for emission: default: photons s$^{-1}$ cm$^{-2}$ sr$^{-1}$ and ALT: erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Vida modified the existing emission_maps code in the emission repository of foggie to dynamically get:\n",
    "1. filters: tempreture, density, inflow,outflow, disk, cgm\n",
    "2. resolution for frb maps\n",
    "3. units for emission: default: photons s$^{-1}$ cm$^{-2}$ sr$^{-1}$ and ALT: erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9fbf16-35cf-4d81-8497-6fc98fd4d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vidasaeedzadeh/miniforge3/envs/foggie/lib/python3.12/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import yt\n",
    "import unyt\n",
    "from yt import YTArray\n",
    "from yt.data_objects.level_sets.api import * \n",
    "import argparse\n",
    "import os\n",
    "from astropy.table import Table\n",
    "from astropy.io import ascii\n",
    "import multiprocessing as multi\n",
    "\n",
    "\n",
    "import datetime\n",
    "from scipy import interpolate\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import cmasher as cmr\n",
    "import matplotlib.colors as mcolors\n",
    "import h5py\n",
    "import trident\n",
    "\n",
    "# These imports are FOGGIE-specific files\n",
    "from foggie.utils.consistency import *\n",
    "from foggie.utils.get_run_loc_etc import get_run_loc_etc\n",
    "from foggie.utils.yt_fields import *\n",
    "from foggie.utils.foggie_load import *\n",
    "from foggie.utils.analysis_utils import *\n",
    "\n",
    "# These imports for datashader plots\n",
    "import datashader as dshader\n",
    "from datashader.utils import export_image\n",
    "import datashader.transfer_functions as tf\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from yt.units.yt_array import YTQuantity\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "\n",
    "def generate_foggie_paths(halo, run, snap):\n",
    "    # Define base paths\n",
    "    foggie_base_dir = \"/Users/vidasaeedzadeh/Projects/foggie_data/\"\n",
    "    code_base_path = \"/Users/vidasaeedzadeh/Projects/repositories/foggie/foggie/\"\n",
    "    output_base_dir = \"/Users/vidasaeedzadeh/Projects/foggie_outputs/\"\n",
    "\n",
    "    # Zero-pad the halo number to 6 digits\n",
    "    halo_number = halo.zfill(6)\n",
    "\n",
    "    # Define directory and file paths dynamically\n",
    "    foggie_dir = os.path.join(foggie_base_dir, f\"halo_{halo_number}\", run + '/')\n",
    "    snap_name = os.path.join(foggie_dir, snap, snap)\n",
    "    halo_c_v_name = os.path.join(code_base_path, f\"halo_infos/{halo_number}/{run}/halo_c_v\")\n",
    "    trackname = os.path.join(code_base_path, f\"halo_tracks/{halo_number}/nref11n_selfshield_15/halo_track_200kpc_nref9\")\n",
    "\n",
    "    # Output directory (adjust based on needs)\n",
    "    output_dir = output_base_dir\n",
    "\n",
    "    # Return paths\n",
    "    return foggie_dir,code_base_path, snap_name, halo_c_v_name, trackname, output_dir\n",
    "\n",
    "# specify halo and snapshot\n",
    "halo = '8508'\n",
    "run = 'nref11c_nref9f'#'ludicrous/nref11c_nref9f.enhance'\n",
    "snap = 'DD2520'\n",
    "\n",
    "foggie_dir,code_path, snap_name, halo_c_v_name, trackname, output_dir = generate_foggie_paths(halo, run, snap)\n",
    "\n",
    "\n",
    "\n",
    "# System and plotting settings\n",
    "system = ''  # System you're using\n",
    "plot = 'emission_FRB'  # Options: emission_map, emission_map_vbins, or emission_FRB or emission_FRB_binsmearing\n",
    "ions = ['Halpha','C II','C III','C IV', 'O VI']#['Lyalpha', 'Halpha', 'CIII', 'CIV', 'OVI','SiII','SiIII','SiIV','MgII'] \n",
    "trident_ions =  ['H I','C II','C III','C IV', 'O VI']\n",
    "Dragonfly_limit = False\n",
    "Aspera_limit = False\n",
    "save_suffix = \"\"\n",
    "file_suffix = \"\"\n",
    "\n",
    "\n",
    "# Filtering settings (optional)\n",
    "segmentation_filter='radial_velocity' # for categorizing inflow vs outflow it can also be 'metallicity'\n",
    "filter_type = None  # Type of filter, e.g., 'temperature', 'density', cgm_disk\n",
    "filter_value = None  # Value for the filter, e.g., 1e4 for temperature < 1e4 K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6ddf3fd-85d4-46f2-8826-2e54febeb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Trident ion fields\n",
    "def add_ion_fields(ds):\n",
    "    trident.add_ion_fields(ds, ions=trident_ions)\n",
    "    return ds\n",
    "\n",
    "def scale_by_metallicity(values,assumed_Z,wanted_Z):\n",
    "    # The Cloudy calculations assumed a single metallicity (typically solar).\n",
    "    # This function scales the emission by the metallicity of the gas itself to\n",
    "    # account for this discrepancy.\n",
    "    wanted_ratio = (10.**(wanted_Z))/(10.**(assumed_Z))\n",
    "    return values*wanted_ratio\n",
    "\n",
    "def make_Cloudy_table(table_index):\n",
    "    # This function takes all of the Cloudy files and compiles them into one table\n",
    "    # for use in the emission functions\n",
    "    # table_index is the column in the Cloudy output files that is being read.\n",
    "    # each table_index value corresponds to a different emission line\n",
    "\n",
    "    # this is the the range and number of bins for which Cloudy was run\n",
    "    # i.e. the temperature and hydrogen number densities gridded in the\n",
    "    # Cloudy run. They must match or the table will be incorrect.\n",
    "    hden_n_bins, hden_min, hden_max = 15, -5, 2 #17, -6, 2 #23, -9, 2\n",
    "    T_n_bins, T_min, T_max = 51, 3, 8 #71, 2, 8\n",
    "\n",
    "    hden=np.linspace(hden_min,hden_max,hden_n_bins)\n",
    "    T=np.linspace(T_min,T_max, T_n_bins)\n",
    "    table = np.zeros((hden_n_bins,T_n_bins))\n",
    "    for i in range(hden_n_bins):\n",
    "            table[i,:]=[float(l.split()[table_index]) for l in open(cloudy_path%(i+1)) if l[0] != \"#\"]\n",
    "    return hden,T,table\n",
    "\n",
    "def make_Cloudy_table_thin(table_index):\n",
    "    hden_n_bins, hden_min, hden_max = 17, -5, 2\n",
    "    T_n_bins, T_min, T_max = 51, 3, 8 #71, 2, 8\n",
    "\n",
    "    hden=np.linspace(hden_min,hden_max,hden_n_bins)\n",
    "    T=np.linspace(T_min,T_max, T_n_bins)\n",
    "    table = np.zeros((hden_n_bins,T_n_bins))\n",
    "    for i in range(hden_n_bins):\n",
    "            table[i,:]=[float(l.split()[table_index]) for l in open(cloudy_path_thin%(i+1)) if l[0] != \"#\"]\n",
    "    return hden,T,table\n",
    "\n",
    "\n",
    "def _Emission_LyAlpha(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_LA(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10**dia1) * ((10.0**H_N)**2.0)\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 1.63e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "\n",
    "def _Emission_HAlpha(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data['H_nuclei_density']))\n",
    "    Temperature = np.log10(np.array(data['Temperature']))\n",
    "    dia1 = bl_HA(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.**dia1) * ((10.**H_N)**2.0)\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 3.03e-12)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "    \n",
    "def _Emission_CII_1335(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_CII_1335(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 2.03e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "\n",
    "def _Emission_CIII_977(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_CIII_977(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 2.03e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "    \n",
    "def _Emission_CIII_1910(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_CIII_1910(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 2.03e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "def _Emission_CIV_1548(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_CIV_1(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 1.28e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "\n",
    "def _Emission_OVI(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_OVI_1(H_N, Temperature)\n",
    "    dia2 = bl_OVI_2(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    dia2[idx] = -200.\n",
    "    emission_line = ((10.0**dia1) + (10**dia2)) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 1.92e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "\n",
    "def _Emission_SiIII_1207(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_SiIII_1207(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4. * np.pi * 1.65e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "\n",
    "def _Emission_SiII_1814(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_SiIII_1207(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4.*np.pi*1.65e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "def _Emission_SiIV_1394(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_SiIII_1207(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4.*np.pi*1.65e-11)\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "def _Emission_MgII_2796(field, data, unit_system='default'):\n",
    "    H_N = np.log10(np.array(data[\"H_nuclei_density\"]))\n",
    "    Temperature = np.log10(np.array(data[\"Temperature\"]))\n",
    "    dia1 = bl_SiIII_1207(H_N, Temperature)\n",
    "    idx = np.isnan(dia1)\n",
    "    dia1[idx] = -200.\n",
    "    emission_line = (10.0**dia1) * ((10.0**H_N)**2.0)\n",
    "    emission_line = scale_by_metallicity(emission_line, 0.0, np.log10(np.array(data['metallicity'])))\n",
    "    \n",
    "    if unit_system == 'default':\n",
    "        emission_line = emission_line / (4.*np.pi*1.65e-11) # what should be instead of 1.65e-11 for MgII? or anyother new element I use?\n",
    "        return emission_line * ytEmU\n",
    "    elif unit_system == 'ALT':\n",
    "        emission_line = emission_line / (4. * np.pi)\n",
    "        emission_line = emission_line / 4.25e10\n",
    "        return emission_line * ytEmUALT\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a53bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Disk finder and remover\n",
    "\n",
    "halo_dict = {   '2392'  :  'Hurricane' ,\n",
    "                '2878'  :  'Cyclone' ,\n",
    "                '4123'  :  'Blizzard' ,\n",
    "                '5016'  :  'Squall' ,\n",
    "                '5036'  :  'Maelstrom' ,\n",
    "                '8508'  :  'Tempest',\n",
    "                '002392'  :  'Hurricane' ,\n",
    "                '002878'  :  'Cyclone' ,\n",
    "                '004123'  :  'Blizzard' ,\n",
    "                '005016'  :  'Squall' ,\n",
    "                '005036'  :  'Maelstrom' ,\n",
    "                '008508'  :  'Tempest' }\n",
    "\n",
    "def halo_id_to_name(halo_id):\n",
    "    return halo_dict[str(halo_id)]\n",
    "    \n",
    "def read_virial_mass_file(halo_id,snapshot,refinement_scheme,codedir,key=\"radius\"):\n",
    "    '''\n",
    "    Read in single entries from the virial mass file for a certain key for 1 snapshot\n",
    "    Keys include: ['redshift', 'snapshot', 'radius', 'total_mass', 'dm_mass', 'stars_mass',\n",
    "    'young_stars_mass', 'old_stars_mass', 'gas_mass', 'gas_metal_mass', 'gas_H_mass',\n",
    "    'gas_HI_mass', 'gas_HII_mass', 'gas_CII_mass', 'gas_CIII_mass', 'gas_CIV_mass',\n",
    "    'gas_OVI_mass', 'gas_OVII_mass', 'gas_MgII_mass', 'gas_SiII_mass', 'gas_SiIII_mass', \n",
    "    'gas_SiIV_mass', 'gas_NeVIII_mass']\n",
    "    '''\n",
    "    from astropy.table import Table\n",
    "    masses_dir = codedir+\"foggie/halo_infos/\"+halo_id+\"/\"+refinement_scheme+\"/rvir_masses.hdf5\"\n",
    "    rvir_masses = Table.read(masses_dir, path='all_data')\n",
    "    \n",
    "    return rvir_masses[key][rvir_masses['snapshot']==snapshot][-1]\n",
    "    \n",
    "    \n",
    "def get_cgm_density_cut(ds,cut_type=\"comoving_density\",additional_factor=2.,code_dir=None):\n",
    "    '''\n",
    "    Get a density cutoff to separate the galaxy from the CGM\n",
    "    '''\n",
    "    if cut_type==\"comoving_density\":\n",
    "        z = ds.get_parameter('CosmologyCurrentRedshift')\n",
    "        cgm_density_cut = 0.1 *additional_factor* cgm_density_max * (1+z)**3\n",
    "    elif cut_type==\"relative_density\":\n",
    "        try: Rvir = read_virial_mass_file(gal_id, \"RD0042\",\"nref11c_nref9f\",code_dir)\n",
    "        except:\n",
    "            print(\"Warning: Could not read rvir file for this halo...\")\n",
    "            Rvir = 300.\n",
    "        print(\"Rvir set to:\",Rvir)\n",
    "        #ds, refine_box = foggie_load(snap_name, trackname, halo_c_v_name=halo_c_v_name, do_filter_particles=True,disk_relative=True,particle_type_for_angmom=particle_type_for_angmom,smooth_AM_name = smooth_AM_name)\n",
    "        sphere = ds.sphere(center=ds.halo_center_kpc, radius=(Rvir, 'kpc')) \n",
    "        z = ds.get_parameter('CosmologyCurrentRedshift')\n",
    "        mask = ((sphere['gas','radius_corrected']>50./(1+z)) & (sphere['gas','density']<=cgm_density_max*(1+z)**3))\n",
    "        \n",
    "        mean_density = np.average( sphere['gas','density'][mask], weights=sphere['cell_volume'][mask])\n",
    "        stdv_density = np.sqrt( np.average( np.power(sphere['gas','density'][mask] - mean_density , 2) , weights=sphere['cell_volume'][mask]))\n",
    "        cgm_density_cut = mean_density + additional_factor * stdv_density \n",
    "    else:\n",
    "        # Define the density cut between disk and CGM to vary smoothly between 1 and 0.1 between z = 0.5 and z = 0.25,\n",
    "        # with it being 1 at higher redshifts and 0.1 at lower redshifts\n",
    "        # Cassi's original definition\n",
    "        current_time = ds.current_time.in_units('Myr').v\n",
    "        if (current_time<=7091.48):\n",
    "            density_cut_factor = 20. - 19.*current_time/7091.48\n",
    "        elif (current_time<=8656.88):\n",
    "            density_cut_factor = 1.\n",
    "        elif (current_time<=10787.12):\n",
    "            density_cut_factor = 1. - 0.9*(current_time-8656.88)/2130.24\n",
    "        else:\n",
    "            density_cut_factor = 0.1\n",
    "        \n",
    "        cgm_density_cut = cgm_density_max * density_cut_factor * additional_factor\n",
    "        z = ds.get_parameter('CosmologyCurrentRedshift')\n",
    "        print(\"Cassi's cut is:\",cgm_density_cut,\"(comoving would be\",0.1*additional_factor*cgm_density_max*(1+z)**3,\")\")\n",
    "    return cgm_density_cut\n",
    "\n",
    "\n",
    "\n",
    "def find_disk(ds,max_disk_radius=100.,use_comoving_density=True,comoving_scaler=0.2):\n",
    "    cgm_density_cut = get_cgm_density_cut(ds,use_comoving_density,comoving_scaler)\n",
    "\n",
    "\n",
    "    sphere = ds.sphere(center=ds.halo_center_kpc, radius=(max_disk_radius, 'kpc'))\n",
    "    sph_ism = sphere.cut_region(\"obj['density'] > %.3e\" % (cgm_density_cut))\n",
    "    \n",
    "\n",
    "    #Test to identify just the disk\n",
    "    master_clump = Clump(sphere, (\"gas\", \"density\"))\n",
    "    master_clump.add_validator(\"min_cells\", 200)\n",
    "    c_min = sph_ism[\"gas\", \"density\"].min()\n",
    "    c_max = sph_ism[\"gas\", \"density\"].max()\n",
    "    #Force to only find highest level clumps\n",
    "    step = c_max / c_min #100. #2.0\n",
    "\n",
    "    find_clumps(master_clump, c_min, c_max, step)\n",
    "\n",
    "    leaf_clumps=master_clump.leaves\n",
    "    #child_clumps=master_clump.children\n",
    "    current_max=0\n",
    "    for leaf in leaf_clumps:\n",
    "        ncells = np.size(leaf[\"gas\",\"density\"])\n",
    "        if ncells>current_max:\n",
    "            current_max = ncells\n",
    "            disk_clump = leaf\n",
    "\n",
    "\n",
    "    return disk_clump\n",
    "\n",
    "\n",
    "\n",
    "global clump_cell_ids\n",
    "\n",
    "def _masked_field(field,data):\n",
    "    return ~np.isin(data[\"index\",\"cell_id_2\"],clump_cell_ids) #if you want to remove disk\n",
    "    #return np.isin(data[\"index\",\"cell_id_2\"],clump_cell_ids) #if you only want disk\n",
    "    \n",
    "\n",
    "global max_gid\n",
    "global gx_min; global gy_min; global gz_min\n",
    "global gx_max; global gy_max; global gz_max\n",
    "\n",
    "def get_cell_grid_ids(field, data):\n",
    "    gids = data['index','grid_indices'] + 1 #These are different in yt and enzo...\n",
    "    u_id = np.copy(gids)\n",
    "    \n",
    "    idx_dx = data['index','dx']\n",
    "\n",
    "    x_id = np.divide(data['index','x'] - idx_dx/2. , idx_dx)\n",
    "    y_id = np.divide(data['index','y'] - idx_dx/2. , idx_dx)\n",
    "    z_id = np.divide(data['index','z'] - idx_dx/2. , idx_dx)\n",
    "    \n",
    "    \n",
    "    for gid in np.round(np.unique(gids)).astype(int): \n",
    "        if gid<=0: continue\n",
    "        grid_mask = (gids==gid)\n",
    "        if np.size(np.where(grid_mask)[0])<=0: continue\n",
    "\n",
    "        gx = x_id[grid_mask]\n",
    "        gy = y_id[grid_mask]\n",
    "        gz = z_id[grid_mask]\n",
    "\n",
    "        gx = gx - gx_min[gid-1]\n",
    "        gy = gy - gy_min[gid-1]\n",
    "        gz = gz - gz_min[gid-1]\n",
    "\n",
    "\n",
    "        max_x = gx_max[gid-1]-gx_min[gid-1]\n",
    "        max_y = gy_max[gid-1]-gy_min[gid-1]\n",
    "\n",
    "        c_id =  gx+gy*(max_x+1) +gz*(max_x+1)*(max_y+1)\n",
    "\n",
    "        u_id[grid_mask] = np.round(gid + c_id * (max_gid+1)).astype(np.uint64)\n",
    "    return u_id    \n",
    "    \n",
    "\n",
    "\n",
    "def load_disk(ds,clump_file,source_cut=None):\n",
    "    '''\n",
    "    Function to load a disk cut region defined by clump_finder.py\n",
    "    Prior to calling this function, the  cell_grid_ids must be added to the dataset\n",
    "    \n",
    "    '''\n",
    "\n",
    "    global clump_cell_ids\n",
    "    hf = h5py.File(clump_file,'r')\n",
    "    clump_cell_ids = np.round(np.array(hf['cell_ids']).astype(np.uint64))\n",
    "    hf.close()\n",
    "\n",
    "    global max_gid\n",
    "    max_gid=-1\n",
    "    for g,m in ds.all_data().blocks:\n",
    "        if g.id>max_gid: max_gid=g.id\n",
    "    \n",
    "    global gx_min; global gy_min; global gz_min\n",
    "    global gx_max; global gy_max; global gz_max\n",
    "\n",
    "    gx_min = np.zeros((max_gid))\n",
    "    gy_min = np.zeros((max_gid))\n",
    "    gz_min = np.zeros((max_gid))\n",
    "    gx_max = np.zeros((max_gid))\n",
    "    gy_max = np.zeros((max_gid))\n",
    "    gz_max = np.zeros((max_gid))\n",
    "    \n",
    "    for g,m in ds.all_data().blocks:\n",
    "        g_dx = g['index','dx'].max()\n",
    "\n",
    "        gx_min[g.id-1] = (g['index','x'].min() - g_dx/2.)  / g_dx\n",
    "        gy_min[g.id-1] = (g['index','y'].min() - g_dx/2.)  / g_dx\n",
    "        gz_min[g.id-1] = (g['index','z'].min() - g_dx/2.)  / g_dx\n",
    "\n",
    "        gx_max[g.id-1] = (g['index','x'].max() - g_dx/2.)  / g_dx\n",
    "        gy_max[g.id-1] = (g['index','y'].max() - g_dx/2.)  / g_dx\n",
    "        gz_max[g.id-1] = (g['index','z'].max() - g_dx/2.)  / g_dx \n",
    "\n",
    "    ds.add_field(\n",
    "        ('index', 'cell_id_2'),\n",
    "          function=get_cell_grid_ids,\n",
    "          sampling_type='cell',\n",
    "          force_override=True\n",
    "    )\n",
    "\n",
    "    ds.add_field(\n",
    "        (\"index\",\"masked_field\"),\n",
    "        function=_masked_field,\n",
    "        sampling_type=\"cell\",\n",
    "        units=\"\",\n",
    "        force_override=True\n",
    "    )\n",
    "\n",
    "    if source_cut is None:\n",
    "        source_cut = ds.all_data()\n",
    "    masked_region = source_cut.cut_region([\"obj['index','masked_field']\"])\n",
    "\n",
    "    return masked_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f8a61ce-63d1-41f4-bbaa-de7debd38fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_ds(box):\n",
    "    '''This function filters the yt data object passed in as 'box' into inflow and outflow regions,\n",
    "    based on metallicity, and returns the box filtered into these regions.'''\n",
    "\n",
    "    if (segmentation_filter=='metallicity'):\n",
    "        box_#inflow = box.include_below(('gas','metallicity'), 0.01, 'Zsun')\n",
    "        box_outflow = box.include_above(('gas','metallicity'), 1., 'Zsun')\n",
    "        box_neither = box.include_above(('gas','metallicity'), 0.01, 'Zsun')\n",
    "        box_neither = box_neither.include_below(('gas','metallicity'), 1., 'Zsun')\n",
    "    elif (segmentation_filter=='radial_velocity'):\n",
    "        box_inflow = box.include_below(('gas','radial_velocity_corrected'), -100., 'km/s')\n",
    "        box_outflow = box.include_above(('gas','radial_velocity_corrected'), 200., 'km/s')\n",
    "        box_neither = box.include_above(('gas','radial_velocity_corrected'), -100., 'km/s')\n",
    "        box_neither = box_neither.include_below(('gas','radial_velocity_corrected'), 200., 'km/s')\n",
    "\n",
    "    return box_inflow, box_outflow, box_neither\n",
    "\n",
    "def make_FRB(ds, refine_box, snap, ions, unit_system='default', filter_type=None, filter_value=None,resolution=100):\n",
    "    '''This function takes the dataset 'ds' and the refine box region 'refine_box' and\n",
    "    makes a fixed resolution buffer of surface brightness from edge-on, face-on,\n",
    "    and arbitrary orientation projections of all ions in the list 'ions'.'''\n",
    "\n",
    "    halo_name = halo_dict[str(halo)]\n",
    "\n",
    "    # Determine resolution and bin size\n",
    "    pix_res = float(np.min(refine_box['dx'].in_units('kpc')))\n",
    "    bin_size_kpc = resolution*pix_res\n",
    "    round_bin_size_kpc = round(bin_size_kpc,2)\n",
    "    # Ensure fov_kpc is in kpc\n",
    "    if not hasattr(ds.refine_width, 'in_units'):\n",
    "        fov_kpc = YTQuantity(ds.refine_width, 'kpc')  # Wrap in YTQuantity with units\n",
    "    else:\n",
    "        fov_kpc = ds.refine_width.in_units('kpc')  # Convert to kpc if it has units\n",
    "    \n",
    "    # Convert to numeric value (without units) for calculations\n",
    "    fov_kpc_value = fov_kpc.v\n",
    "\n",
    "    res= int(fov_kpc_value/bin_size_kpc)\n",
    "\n",
    "    # Print for debugging\n",
    "    print(f\"Native resolution (pix_res): {pix_res:.2f} kpc\")\n",
    "    print(f\"Field of view (FOV): {fov_kpc_value:.3f} kpc\")\n",
    "    print(f\"Adjusted bin size (bin_size_kpc): {bin_size_kpc:.2f} kpc\")\n",
    "    print(f\"Adjusted number of bins (res): {res}\")\n",
    "    \n",
    "    print('z=%.1f' % ds.get_parameter('CosmologyCurrentRedshift', 1))\n",
    "\n",
    "    # Apply inflow/outflow or disk/CGM filtering using the filter_ds function if specified\n",
    "    if filter_type == 'inflow_outflow':\n",
    "        # Apply the inflow/outflow filtering\n",
    "        box_inflow, box_outflow, box_neither = filter_ds(ds.all_data())\n",
    "        data_sources = {'inflow': box_inflow, 'outflow': box_outflow, 'neither': box_neither}\n",
    "\n",
    "    elif filter_type == 'disk_cgm':\n",
    "        # Apply the disk/CGM filtering\n",
    "        box_cgm = load_disk(ds,clump_file,source_cut=None)\n",
    "        data_sources = {'cgm': box_cgm}\n",
    "        \n",
    "    else:\n",
    "        # Standard filtering or no filter\n",
    "        data_sources = {'all': ds.all_data()}\n",
    "        if filter_type and filter_value:\n",
    "            if filter_type == 'temperature':\n",
    "                data_sources['all'] = data_sources['all'].cut_region([f\"(obj['gas', 'temperature'] < {filter_value})\"])\n",
    "            elif filter_type == 'density':\n",
    "                data_sources['all'] = data_sources['all'].cut_region([f\"(obj['gas', 'density'] > {filter_value})\"])\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported filter type. Supported types: 'temperature', 'density'.\")\n",
    "\n",
    "    # Define the unit string based on unit_system\n",
    "    if unit_system == 'default':\n",
    "        unit_label = '[photons s$^{-1}$ cm$^{-2}$ sr$^{-1}$]'\n",
    "    elif unit_system == 'ALT':\n",
    "        unit_label = '[erg s$^{-1}$ cm$^{-2}$ arcsec$^{-2}$]'\n",
    "    else:\n",
    "        raise ValueError(\"Invalid unit_system specified. Use 'default' or 'ALT'.\")\n",
    "\n",
    "    # Create HDF5 file for saving emission maps\n",
    "    save_path = prefix + f'FRBs/res_{bin_size_kpc:.2f}/' \n",
    "    os.makedirs(save_path, exist_ok=True)  # Ensure the directory exists\n",
    "    f = h5py.File(save_path + halo_name + '_emission_maps' + save_suffix + '.hdf5', 'a')\n",
    "    grp = f.create_group('z=%.1f' % ds.get_parameter('CosmologyCurrentRedshift', 1))\n",
    "    grp.attrs.create(\"image_extent_kpc\", ds.refine_width)\n",
    "    grp.attrs.create(\"redshift\", ds.get_parameter('CosmologyCurrentRedshift'))\n",
    "    grp.attrs.create(\"halo_name\", halo_name)\n",
    "    grp.attrs.create(\"emission_units\", unit_label)\n",
    "    grp.attrs.create(\"gas_density_units\", 'g/cm^2')\n",
    "    grp.attrs.create(\"stars_density_units\", 'Msun/kpc^2')\n",
    "    grp.attrs.create(\"bin_size_kpc\", round_bin_size_kpc)\n",
    "    grp.attrs.create(\"number_of_bins\", res)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Loop through ions and create projections for each region\n",
    "    for region, data_source in data_sources.items():\n",
    "        for ion in ions:\n",
    "            print(ion)\n",
    "\n",
    "            #Edge-on projection\n",
    "            proj_edge = yt.ProjectionPlot(ds, ds.x_unit_disk, ('gas', 'Emission_' + ions_dict[ion]),\n",
    "                                          center=ds.halo_center_kpc, data_source=data_source,width=(ds.refine_width, 'kpc'),\n",
    "                                          north_vector=ds.z_unit_disk, buff_size=[res, res], method = 'integrate', weight_field=None)\n",
    "            frb_edge = proj_edge.frb[('gas', 'Emission_' + ions_dict[ion])]\n",
    "            dset1 = grp.create_dataset(f\"{ion}_emission_edge_{region}\", data=frb_edge)\n",
    "\n",
    "            # Set colormap and save projection plot\n",
    "            mymap = cmr.get_sub_cmap('cmr.flamingo', 0.2, 0.8)\n",
    "            mymap.set_bad(\"#421D0F\")\n",
    "            proj_edge.set_cmap('Emission_' + ions_dict[ion], mymap)\n",
    "            proj_edge.set_zlim('Emission_' + ions_dict[ion], zlim_dict[ion][0], zlim_dict[ion][1])\n",
    "            proj_edge.set_colorbar_label('Emission_' + ions_dict[ion], label_dict[ion] + ' Emission ' + unit_label)\n",
    "            proj_edge.set_font_size(20)\n",
    "            proj_edge.annotate_timestamp(corner='upper_left', redshift=True, time=True, draw_inset_box=True)\n",
    "            proj_edge.save(save_path + f'{snap}_{ion}_emission_map_edge-on_{region}' + save_suffix + '.png')\n",
    "\n",
    "            # Face-on projection\n",
    "            proj_face = yt.ProjectionPlot(ds, ds.z_unit_disk, ('gas', 'Emission_' + ions_dict[ion]),\n",
    "                                          center=ds.halo_center_kpc, data_source=data_source,width=(ds.refine_width, 'kpc'),\n",
    "                                          north_vector=ds.x_unit_disk, buff_size=[res, res],weight_field=None)\n",
    "            frb_face = proj_face.frb[('gas', 'Emission_' + ions_dict[ion])]\n",
    "            dset2 = grp.create_dataset(f\"{ion}_emission_face_{region}\", data=frb_face)\n",
    "\n",
    "            # Set colormap and save projection plot\n",
    "            proj_face.set_cmap('Emission_' + ions_dict[ion], mymap)\n",
    "            proj_face.set_zlim('Emission_' + ions_dict[ion], zlim_dict[ion][0], zlim_dict[ion][1])\n",
    "            proj_face.set_colorbar_label('Emission_' + ions_dict[ion], label_dict[ion] + ' Emission ' + unit_label)\n",
    "            proj_face.set_font_size(20)\n",
    "            proj_face.annotate_timestamp(corner='upper_left', redshift=True, time=True, draw_inset_box=True)\n",
    "            proj_face.save(save_path + f'{snap}_{ion}_emission_map_face-on_{region}' + save_suffix + '.png')\n",
    "\n",
    "    # Close the HDF5 file after saving the datasets\n",
    "    print('finished')\n",
    "    f.close()\n",
    "\n",
    "def emission_map_vbins(ds, snap, ions,unit_system='default', filter_type=None, filter_value=None):\n",
    "    '''Makes many emission maps for each ion in 'ions', oriented both edge-on and face-on, for each line-of-sight velocity bin.'''\n",
    "\n",
    "    vbins = np.arange(-500., 550., 50.)  # Velocity bins\n",
    "    ad = ds.all_data()\n",
    "\n",
    "    for i in range(len(ions)):\n",
    "        ion = ions[i]\n",
    "\n",
    "        # Choose colormap based on ion and emission limits\n",
    "        if (ion == 'Halpha') and Dragonfly_limit:\n",
    "            cmap1 = cmr.take_cmap_colors('cmr.flamingo', 9, cmap_range=(0.4, 0.8), return_fmt='rgba')\n",
    "            cmap2 = cmr.take_cmap_colors('cmr.neutral_r', 3, cmap_range=(0.2, 0.6), return_fmt='rgba')\n",
    "            cmap = np.hstack([cmap2, cmap1])\n",
    "            mymap = mcolors.LinearSegmentedColormap.from_list('cmap', cmap)\n",
    "        elif (ion == 'OVI') and Aspera_limit:\n",
    "            cmap1 = cmr.take_cmap_colors('cmr.flamingo', 4, cmap_range=(0.4, 0.8), return_fmt='rgba')\n",
    "            cmap2 = cmr.take_cmap_colors('cmr.neutral_r', 6, cmap_range=(0.2, 0.6), return_fmt='rgba')\n",
    "            cmap = np.hstack([cmap2, cmap1])\n",
    "            mymap = mcolors.LinearSegmentedColormap.from_list('cmap', cmap)\n",
    "        else:\n",
    "            mymap = cmr.get_sub_cmap('cmr.flamingo', 0.2, 0.8)\n",
    "        mymap.set_bad(mymap.colors[0])\n",
    "\n",
    "        # Loop through each velocity bin\n",
    "        for v in range(len(vbins) - 1):\n",
    "            # Filter the data by the current velocity bin\n",
    "            vbox = ds.cut_region(ad, [f\"obj[('gas', 'vx_disk')] > {vbins[v]:.1f}\"])\n",
    "            vbox = ds.cut_region(vbox, [f\"obj[('gas', 'vx_disk')] < {vbins[v+1]:.1f}\"])\n",
    "\n",
    "            # Apply filtering if specified (e.g., temperature or density cut)\n",
    "            if filter_type and filter_value:\n",
    "                if filter_type == 'temperature':\n",
    "                    vbox = vbox.cut_region([f\"(obj['gas', 'temperature'] < {filter_value})\"])\n",
    "                elif filter_type == 'density':\n",
    "                    vbox = vbox.cut_region([f\"(obj['gas', 'density'] > {filter_value})\"])\n",
    "                else:\n",
    "                    raise ValueError(\"Unsupported filter type. Supported types: 'temperature', 'density'.\")\n",
    "\n",
    "            # Edge-on projection\n",
    "            proj_edge = yt.ProjectionPlot(ds, ds.x_unit_disk, ('gas', 'Emission_' + ions_dict[ion]), \n",
    "                                          center=ds.halo_center_kpc, width=(ds.refine_width, 'kpc'),\n",
    "                                          north_vector=ds.z_unit_disk, data_source=vbox)\n",
    "            proj_edge.set_cmap('Emission_' + ions_dict[ion], mymap)\n",
    "            proj_edge.set_zlim('Emission_' + ions_dict[ion], zlim_dict[ion][0], zlim_dict[ion][1])\n",
    "            proj_edge.set_colorbar_label('Emission_' + ions_dict[ion], label_dict[ion] + 'Emission' + unit_label)\n",
    "            proj_edge.set_font_size(20)\n",
    "            proj_edge.annotate_title(f'$%d < v_{{\\\\rm los}} < %d$' % (vbins[v], vbins[v+1]))\n",
    "            proj_edge.annotate_timestamp(corner='upper_left', redshift=True, time=True, draw_inset_box=True)\n",
    "            proj_edge.save(prefix + 'EmissionMap/' + snap + '_' + ion + '_emission_map_edge-on_vbin' + str(v) + save_suffix + '.png')\n",
    "\n",
    "            # Face-on projection\n",
    "            proj_face = yt.ProjectionPlot(ds, ds.z_unit_disk, ('gas', 'Emission_' + ions_dict[ion]), \n",
    "                                          center=ds.halo_center_kpc, width=(ds.refine_width, 'kpc'),\n",
    "                                          north_vector=ds.x_unit_disk, data_source=vbox)\n",
    "            proj_face.set_cmap('Emission_' + ions_dict[ion], mymap)\n",
    "            proj_face.set_zlim('Emission_' + ions_dict[ion], zlim_dict[ion][0], zlim_dict[ion][1])\n",
    "            proj_face.set_colorbar_label('Emission_' + ions_dict[ion], label_dict[ion] + 'Emission' + unit_label)\n",
    "            proj_face.set_font_size(20)\n",
    "            proj_face.annotate_title(f'$%d < v_{{\\\\rm los}} < %d$' % (vbins[v], vbins[v+1]))\n",
    "            proj_face.annotate_timestamp(corner='upper_left', redshift=True, time=True, draw_inset_box=True)\n",
    "            proj_face.save(prefix + 'EmissionMap/' + snap + '_' + ion + '_emission_map_face-on_vbin' + str(v) + save_suffix + '.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "013f8ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_mass_FRB(ds, refine_box, snap, ions, filter_type=None, filter_value=None, resolution=100):\n",
    "    '''This function calculates and saves mass FRBs and total mass for each ion.'''\n",
    "\n",
    "    halo_name = halo_dict[str(halo)]\n",
    "\n",
    "    # Determine resolution and bin size\n",
    "    pix_res = float(np.min(refine_box['dx'].in_units('kpc')))\n",
    "    bin_size_kpc = resolution*pix_res\n",
    "    round_bin_size_kpc = round(bin_size_kpc,2)\n",
    "\n",
    "    # Ensure fov_kpc is in kpc\n",
    "    if not hasattr(ds.refine_width, 'in_units'):\n",
    "        fov_kpc = YTQuantity(ds.refine_width, 'kpc')  # Wrap in YTQuantity with units\n",
    "    else:\n",
    "        fov_kpc = ds.refine_width.in_units('kpc')  # Convert to kpc if it has units\n",
    "    \n",
    "    # Convert to numeric value (without units) for calculations\n",
    "    fov_kpc_value = fov_kpc.v\n",
    "\n",
    "    res= int(fov_kpc_value/bin_size_kpc)\n",
    "\n",
    "    # Print for debugging\n",
    "    print(f\"Native resolution (pix_res): {pix_res:.2f} kpc\")\n",
    "    print(f\"Field of view (FOV): {fov_kpc_value:.3f} kpc\")\n",
    "    print(f\"Adjusted bin size (bin_size_kpc): {bin_size_kpc:.2f} kpc\")\n",
    "    print(f\"Adjusted number of bins (res): {res}\")\n",
    "\n",
    "    # Apply filtering (if specified)\n",
    "    if filter_type == 'inflow_outflow':\n",
    "        box_inflow, box_outflow, box_neither = filter_ds(ds.all_data())\n",
    "        data_sources = {'inflow': box_inflow, 'outflow': box_outflow, 'neither': box_neither}\n",
    "    elif filter_type == 'disk_cgm':\n",
    "        box_disk, box_cgm = filter_ds_disk_cgm(ds)\n",
    "        data_sources = {'disk': box_disk, 'cgm': box_cgm}\n",
    "    else:\n",
    "        data_sources = {'all': ds.all_data()}\n",
    "        if filter_type and filter_value:\n",
    "            if filter_type == 'temperature':\n",
    "                data_sources['all'] = data_sources['all'].cut_region([f\"(obj['gas', 'temperature'] < {filter_value})\"])\n",
    "            elif filter_type == 'density':\n",
    "                data_sources['all'] = data_sources['all'].cut_region([f\"(obj['gas', 'density'] > {filter_value})\"])\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported filter type. Supported types: 'temperature', 'density'.\")\n",
    "\n",
    "    # Create HDF5 file for saving mass maps\n",
    "    save_path = prefix + f'FRBs/res_{bin_size_kpc:.2f}/' \n",
    "    os.makedirs(save_path, exist_ok=True)  # Ensure the directory exists\n",
    "    f = h5py.File(save_path + halo_name + '_emission_maps' + save_suffix + '.hdf5', 'a')\n",
    "    # Check if the group already exists\n",
    "    redshift_group_name = 'z=%.1f' % ds.get_parameter('CosmologyCurrentRedshift', 1)\n",
    "    if redshift_group_name not in f:\n",
    "        grp = f.create_group(redshift_group_name)\n",
    "        grp.attrs.create(\"image_extent_kpc\", ds.refine_width)\n",
    "        grp.attrs.create(\"redshift\", ds.get_parameter('CosmologyCurrentRedshift'))\n",
    "        grp.attrs.create(\"halo_name\", halo_name)\n",
    "        grp.attrs.create(\"bin_size_kpc\", round_bin_size_kpc)\n",
    "        grp.attrs.create(\"number_of_bins\", res)\n",
    "    else:\n",
    "        grp = f[redshift_group_name]  # Open the existing group\n",
    "\n",
    "    # Compute pixel area in cm^2\n",
    "    pixel_area_kpc2 = (fov_kpc / res) ** 2  # Pixel area in kpc^2\n",
    "    pixel_area_cm2 = pixel_area_kpc2.in_units('cm**2')  # Convert to cm^2\n",
    "\n",
    "    # Loop through ions and create projections for each region\n",
    "    for region, data_source in data_sources.items():\n",
    "        for ion in ions:\n",
    "            print(f\"Processing ion: {ion}\")\n",
    "\n",
    "            # Replace mass field with ion density\n",
    "            density_field = ('gas', ions_density_dict[ion]) \n",
    "\n",
    "            # Edge-on projection (surface density)\n",
    "            proj_edge = yt.ProjectionPlot(ds, ds.x_unit_disk, density_field,\n",
    "                                          center=ds.halo_center_kpc, data_source=data_source,\n",
    "                                          width=(ds.refine_width, 'kpc'), north_vector=ds.z_unit_disk,\n",
    "                                          buff_size=[res, res], weight_field=None)\n",
    "            frb_edge = proj_edge.frb[density_field]  # Surface density in g/cm^2\n",
    "            frb_edge_mass = (frb_edge * pixel_area_cm2).in_units('Msun') \n",
    "            # Compute total mass for edge-on projection\n",
    "            total_mass_edge = (frb_edge * pixel_area_cm2).sum().in_units('Msun')  # Convert to solar masses\n",
    "\n",
    "            # Save mass frb and total mass in HDF5\n",
    "            dset1 = grp.create_dataset(f\"{ion}_mass_edge_{region}\", data=frb_edge_mass)\n",
    "            dset1.attrs.create(\"total_mass_Msun\", total_mass_edge)\n",
    "\n",
    "            # Face-on projection (surface density)\n",
    "            proj_face = yt.ProjectionPlot(ds, ds.z_unit_disk, density_field,\n",
    "                                          center=ds.halo_center_kpc, data_source=data_source,\n",
    "                                          width=(ds.refine_width, 'kpc'), north_vector=ds.x_unit_disk,\n",
    "                                          buff_size=[res, res], weight_field=None)\n",
    "            frb_face = proj_face.frb[density_field]  # Surface density in g/cm^2\n",
    "            frb_face_mass = (frb_face* pixel_area_cm2).in_units('Msun') \n",
    "            # Compute total mass for face-on projection\n",
    "            total_mass_face = (frb_face * pixel_area_cm2).sum().in_units('Msun')  # Convert to solar masses\n",
    "\n",
    "            # Save surface density and total mass in HDF5\n",
    "            dset2 = grp.create_dataset(f\"{ion}_mass_face_{region}\", data=frb_face_mass)\n",
    "            dset2.attrs.create(\"total_mass_Msun\", total_mass_face)\n",
    "\n",
    "            print(f\"Edge total mass for {ion}: {total_mass_edge}\")\n",
    "            print(f\"Face total mass for {ion}: {total_mass_face}\")\n",
    "\n",
    "    # Close the HDF5 file after saving the datasets\n",
    "    print('Mass FRBs finished')\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99d41d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [INFO     ] 2025-01-15 13:39:56,118 Parameters: current_time              = 639.44151531954\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,119 Parameters: domain_dimensions         = [256 256 256]\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,119 Parameters: domain_left_edge          = [0. 0. 0.]\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,119 Parameters: domain_right_edge         = [1. 1. 1.]\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,119 Parameters: cosmological_simulation   = 1\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,120 Parameters: current_redshift          = 5.0084873179923e-06\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,120 Parameters: omega_lambda              = 0.715\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,120 Parameters: omega_matter              = 0.285\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,120 Parameters: omega_radiation           = 0\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,120 Parameters: hubble_constant           = 0.695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foggie_dir:  /Users/vidasaeedzadeh/Projects/foggie_data/halo_008508/nref11c_nref9f/\n",
      "snap_name /Users/vidasaeedzadeh/Projects/foggie_data/halo_008508/nref11c_nref9f/DD2520/DD2520\n",
      "Opening snapshot /Users/vidasaeedzadeh/Projects/foggie_data/halo_008508/nref11c_nref9f/DD2520/DD2520\n",
      "get_refine_box: using this location:         col1          col2     col3     col4    col5     col6     col7  col8\n",
      "------------------- -------- -------- ------- -------- -------- ------- ----\n",
      "4.4408920985006e-16 0.488865 0.470316 0.50854 0.490865 0.472316 0.51054    9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing Hierarchy : 100%|██████████| 7623/7623 [00:00<00:00, 28054.33it/s]\n",
      "yt : [INFO     ] 2025-01-15 13:39:56,573 Gathering a field list (this may take a moment.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This snapshot is not in the halo_c_v file, calculating halo center...\n",
      "get_halo_center: code_length code_velocity\n",
      "get_halo_center: obtained the spherical region\n",
      "get_halo_center: extracted the DM density\n",
      "get_halo_center: we have obtained the preliminary center\n",
      "got the velocities\n",
      "get_halo_center: located the main halo at: [0.4898500442504883, 0.47119617462158203, 0.5095453262329102] [unyt_quantity(0.00134392, 'code_velocity'), unyt_quantity(-0.00192745, 'code_velocity'), unyt_quantity(0.00080744, 'code_velocity')]\n",
      "filtering young_stars particles...\n",
      "filtering young_stars3 particles...\n",
      "filtering young_stars8 particles...\n",
      "filtering old_stars particles...\n",
      "filtering stars particles...\n",
      "filtering dm particles...\n",
      "using particle type  young_stars  to derive angular momentum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [WARNING  ] 2025-01-15 13:40:08,452 Field ('gas', 'H_p0_number_density') already exists. Not clobbering.\n",
      "yt : [WARNING  ] 2025-01-15 13:40:08,455 Field ('gas', 'H_p0_density') already exists. Not clobbering.\n",
      "yt : [WARNING  ] 2025-01-15 13:40:08,457 Field ('gas', 'H_p0_mass') already exists. Not clobbering.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found angular momentum vector\n",
      "Native resolution (pix_res): 0.27 kpc\n",
      "Field of view (FOV): 287.768 kpc\n",
      "Adjusted bin size (bin_size_kpc): 0.55 kpc\n",
      "Adjusted number of bins (res): 524\n",
      "z=0.0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/Users/vidasaeedzadeh/Projects/foggie_outputs/ions_halo_008508/nref11c_nref9f//Disk/test_Disk.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 187\u001b[0m\n\u001b[1;32m    185\u001b[0m resolution_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m2\u001b[39m]\u001b[38;5;66;03m#10,50,88]\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m reso \u001b[38;5;129;01min\u001b[39;00m resolution_list:\n\u001b[0;32m--> 187\u001b[0m     \u001b[43mload_and_calculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msnap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_system\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreso\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdisk_cgm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#'default'or choose 'ALT' for erg unit\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 29\u001b[0m, in \u001b[0;36mload_and_calculate\u001b[0;34m(snap, ions, unit_system, filter_type, filter_value, resolution)\u001b[0m\n\u001b[1;32m     26\u001b[0m         emission_map_vbins(ds, snap, ions, unit_system\u001b[38;5;241m=\u001b[39munit_system, filter_type\u001b[38;5;241m=\u001b[39mfilter_type, filter_value\u001b[38;5;241m=\u001b[39mfilter_value)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124memission_FRB\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m plot:\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mmake_FRB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefine_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit_system\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munit_system\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilter_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresolution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresolution\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     make_mass_FRB(ds, refine_box, snap, ions, filter_type\u001b[38;5;241m=\u001b[39mfilter_type, filter_value\u001b[38;5;241m=\u001b[39mfilter_value, resolution\u001b[38;5;241m=\u001b[39mresolution)\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mmake_FRB\u001b[0;34m(ds, refine_box, snap, ions, unit_system, filter_type, filter_value, resolution)\u001b[0m\n\u001b[1;32m     52\u001b[0m     data_sources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minflow\u001b[39m\u001b[38;5;124m'\u001b[39m: box_inflow, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutflow\u001b[39m\u001b[38;5;124m'\u001b[39m: box_outflow, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneither\u001b[39m\u001b[38;5;124m'\u001b[39m: box_neither}\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filter_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisk_cgm\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Apply the disk/CGM filtering\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     box_cgm \u001b[38;5;241m=\u001b[39m \u001b[43mload_disk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclump_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43msource_cut\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     data_sources \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgm\u001b[39m\u001b[38;5;124m'\u001b[39m: box_cgm}\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# Standard filtering or no filter\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 163\u001b[0m, in \u001b[0;36mload_disk\u001b[0;34m(ds, clump_file, source_cut)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mFunction to load a disk cut region defined by clump_finder.py\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03mPrior to calling this function, the  cell_grid_ids must be added to the dataset\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m clump_cell_ids\n\u001b[0;32m--> 163\u001b[0m hf \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclump_file\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m clump_cell_ids \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(np\u001b[38;5;241m.\u001b[39marray(hf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_ids\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint64))\n\u001b[1;32m    165\u001b[0m hf\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/foggie/lib/python3.12/site-packages/h5py/_hl/files.py:561\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    552\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    553\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    554\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    555\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    556\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    557\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    558\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    559\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    560\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 561\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m~/miniforge3/envs/foggie/lib/python3.12/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/Users/vidasaeedzadeh/Projects/foggie_outputs/ions_halo_008508/nref11c_nref9f//Disk/test_Disk.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_calculate(snap, ions, unit_system='default', filter_type=None, filter_value=None, resolution=100):\n",
    "\n",
    "    '''Loads the simulation snapshot and makes the requested plots, with optional filtering.'''\n",
    "\n",
    "    # Load simulation output\n",
    "    if system == 'pleiades_cassi':\n",
    "        print('Copying directory to /tmp')\n",
    "        snap_dir = '/nobackup/clochhaa/tmp/' + halo + '/' + run + '/' + target_dir + '/' + snap\n",
    "        os.makedirs(snap_dir)\n",
    "        snap_name = foggie_dir + run_dir + snap + '/' + snap\n",
    "    else:\n",
    "        snap_name = foggie_dir + snap + '/' + snap\n",
    "    print('snap_name',snap_name)\n",
    "    ds, refine_box = foggie_load(snap_name, trackname, do_filter_particles=True, halo_c_v_name=halo_c_v_name, disk_relative=True, correct_bulk_velocity=True)#, smooth_AM_name=smooth_AM_name)\n",
    "    zsnap = ds.get_parameter('CosmologyCurrentRedshift')\n",
    "    add_ion_fields(ds)\n",
    "\n",
    "    \n",
    "\n",
    "    # Generate emission maps based on the plot type\n",
    "    if 'emission_map' in plot:\n",
    "        if 'vbins' not in plot:\n",
    "            emission_map(ds, snap, ions, filter_type=filter_type, filter_value=filter_value)\n",
    "        else:\n",
    "            # Call velocity-binned emission map function with optional filtering\n",
    "            emission_map_vbins(ds, snap, ions, unit_system=unit_system, filter_type=filter_type, filter_value=filter_value)\n",
    "    \n",
    "    if 'emission_FRB' in plot:\n",
    "        make_FRB(ds, refine_box, snap, ions, unit_system=unit_system, filter_type=filter_type, filter_value=filter_value, resolution=resolution)\n",
    "        make_mass_FRB(ds, refine_box, snap, ions, filter_type=filter_type, filter_value=filter_value, resolution=resolution)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    # if ('feedback' in run) and ('track' in run):\n",
    "    #     foggie_dir = '/nobackup/jtumlins/halo_008508/feedback-track/'\n",
    "    #     run_dir = run + '/'\n",
    "\n",
    "    #set the clump file directory\n",
    "    clump_file = output_dir + 'ions_halo_00' + halo + '/' + run + '/' '/Disk/test_Disk.h5'\n",
    "    \n",
    "    # Set directory for output location, making it if necessary\n",
    "    prefix = output_dir + 'ions_halo_00' + halo + '/' + run + '/'\n",
    "    if not (os.path.exists(prefix)): os.system('mkdir -p ' + prefix)\n",
    "    table_loc = prefix + 'Tables/'\n",
    "\n",
    "    print('foggie_dir: ', foggie_dir)\n",
    "    catalog_dir = code_path + 'halo_infos/00' + halo + '/' + run + '/'\n",
    "    halo_c_v_name = catalog_dir + 'halo_c_v'\n",
    "    #smooth_AM_name = catalog_dir + 'AM_direction_smoothed'\n",
    "\n",
    "    cloudy_path = \"/Users/vidasaeedzadeh/Documents/02-Projects/02-FOGGIE/Cloudy-runs/outputs/test-z0/TEST_z0_HM12_sh_run%i.dat\"\n",
    "    #code_path + \"emission/cloudy_z0_selfshield/sh_z0_HM12_run%i.dat\"\n",
    "    # These are the typical units that Lauren uses\n",
    "    # NOTE: This is a volumetric unit since it's for the emissivity of each cell\n",
    "    # Emission / surface brightness comes from the projections\n",
    "    emission_units = 's**-1 * cm**-3 * steradian**-1'\n",
    "    ytEmU = unyt.second**-1 * unyt.cm**-3 * unyt.steradian**-1\n",
    "\n",
    "    # These are a second set of units that a lot of observers prefer\n",
    "    # NOTE: This is a volumetric unit since it's for the emissivity of each cell\n",
    "    # Emission / surface brightness comes from the projections\n",
    "    emission_units_ALT = 'erg * s**-1 * cm**-3 * arcsec**-2'\n",
    "    ytEmUALT = unyt.erg * unyt.second**-1 * unyt.cm**-3 * unyt.arcsec**-2\n",
    "\n",
    "    ####################################\n",
    "    ## BEGIN CREATING EMISSION FIELDS ##\n",
    "    ####################################\n",
    "\n",
    "    # To make the emissivity fields, you need to follow a number of steps\n",
    "    # 1. Read in the Cloudy values for a given emission line\n",
    "    # 2. Create the n_H and T grids that represent the desired range of values\n",
    "    # 3. Set up interpolation function for the emissivity values across the grids\n",
    "    #    so the code can use the n_H and T values of a simulation grid cell to\n",
    "    #    interpolate the correct emissivity value\n",
    "    # 4. Define the emission field for the line\n",
    "    # 5. Add the line as a value in yt\n",
    "\n",
    "    ############################\n",
    "    # Function to register emission fields with unit options\n",
    "    def register_emission_field_with_unit(field_name, function, emission_units, unit_system):\n",
    "        yt.add_field(\n",
    "            ('gas', field_name),\n",
    "            units=emission_units if unit_system == 'default' else emission_units_ALT,\n",
    "            function=lambda field, data: function(field, data, unit_system=unit_system),\n",
    "            take_log=True,\n",
    "            force_override=True,\n",
    "            sampling_type='cell',\n",
    "        )\n",
    "    \n",
    "    ############################\n",
    "    # Unit system setting (can be passed dynamically)\n",
    "    unit_system = 'default'  # Change this to 'ALT' as needed\n",
    "    \n",
    "    ############################\n",
    "    # H-Alpha\n",
    "    hden_pts, T_pts, table_HA = make_Cloudy_table(2)\n",
    "    hden_pts, T_pts = np.meshgrid(hden_pts, T_pts)\n",
    "    pts = np.array((hden_pts.ravel(), T_pts.ravel())).T\n",
    "    \n",
    "    sr_HA = table_HA.T.ravel()\n",
    "    bl_HA = interpolate.LinearNDInterpolator(pts, sr_HA)\n",
    "    register_emission_field_with_unit('Emission_HAlpha', _Emission_HAlpha, emission_units, unit_system)\n",
    "    \n",
    "    ############################\n",
    "    # Ly-Alpha\n",
    "    hden_pts, T_pts, table_LA = make_Cloudy_table(1)\n",
    "    sr_LA = table_LA.T.ravel()\n",
    "    bl_LA = interpolate.LinearNDInterpolator(pts, sr_LA)\n",
    "    register_emission_field_with_unit('Emission_LyAlpha', _Emission_LyAlpha, emission_units, unit_system)\n",
    "    ############################\n",
    "    # CII 1335\n",
    "    hden_pts, T_pts, table_CII_1335 = make_Cloudy_table(10)\n",
    "    sr_CII_1335 = table_CII_1335.T.ravel()\n",
    "    bl_CII_1335 = interpolate.LinearNDInterpolator(pts, sr_CII_1335)\n",
    "    register_emission_field_with_unit('Emission_CII_1335', _Emission_CII_1335, emission_units, unit_system)\n",
    "    \n",
    "    ############################\n",
    "    # CIII 977\n",
    "    hden_pts, T_pts, table_CIII_977 = make_Cloudy_table(7)\n",
    "    sr_CIII_977 = table_CIII_977.T.ravel()\n",
    "    bl_CIII_977 = interpolate.LinearNDInterpolator(pts, sr_CIII_977)\n",
    "    register_emission_field_with_unit('Emission_CIII_977', _Emission_CIII_977, emission_units, unit_system)\n",
    "\n",
    "    ############################\n",
    "    # CIII 1910\n",
    "    hden_pts, T_pts, table_CIII_1910 = make_Cloudy_table(9)\n",
    "    sr_CIII_1910 = table_CIII_1910.T.ravel()\n",
    "    bl_CIII_1910 = interpolate.LinearNDInterpolator(pts, sr_CIII_1910)\n",
    "    register_emission_field_with_unit('Emission_CIII_1910', _Emission_CIII_1910, emission_units, unit_system)\n",
    "\n",
    "    ############################\n",
    "    # CIV 1548\n",
    "    hden_pts, T_pts, table_CIV_1 = make_Cloudy_table(3)\n",
    "    sr_CIV_1 = table_CIV_1.T.ravel()\n",
    "    bl_CIV_1 = interpolate.LinearNDInterpolator(pts, sr_CIV_1)\n",
    "    register_emission_field_with_unit('Emission_CIV_1548', _Emission_CIV_1548, emission_units, unit_system)\n",
    "    \n",
    "    ############################\n",
    "    # O VI (1032 and 1037 combined)\n",
    "    hden_pts, T_pts, table_OVI_1 = make_Cloudy_table(5)\n",
    "    hden_pts, T_pts, table_OVI_2 = make_Cloudy_table(6)\n",
    "    sr_OVI_1 = table_OVI_1.T.ravel()\n",
    "    sr_OVI_2 = table_OVI_2.T.ravel()\n",
    "    bl_OVI_1 = interpolate.LinearNDInterpolator(pts, sr_OVI_1)\n",
    "    bl_OVI_2 = interpolate.LinearNDInterpolator(pts, sr_OVI_2)\n",
    "    register_emission_field_with_unit('Emission_OVI', _Emission_OVI, emission_units, unit_system)\n",
    "    \n",
    "    ############################\n",
    "    # SiIII 1207\n",
    "    cloudy_path_thin = code_path + \"emission/cloudy_z0_HM05/bertone_run%i.dat\"\n",
    "    hden_pts, T_pts, table_SiIII_1207 = make_Cloudy_table_thin(11)\n",
    "    hden_pts, T_pts = np.meshgrid(hden_pts, T_pts)\n",
    "    pts = np.array((hden_pts.ravel(), T_pts.ravel())).T\n",
    "    sr_SiIII_1207 = table_SiIII_1207.T.ravel()\n",
    "    bl_SiIII_1207 = interpolate.LinearNDInterpolator(pts, sr_SiIII_1207)\n",
    "    register_emission_field_with_unit('Emission_SiIII_1207', _Emission_SiIII_1207, emission_units, unit_system)\n",
    "\n",
    "\n",
    "    ############################\n",
    "    ions_dict = {'Lyalpha':'LyAlpha', 'Halpha':'HAlpha', 'C III':'CIII_1910', 'C II': 'CII_1335',\n",
    "                 'C IV':'CIV_1548','O VI':'OVI', 'Si III':'SiIII_1207'}\n",
    "    ions_density_dict = {'Lyalpha':'LyAlpha', 'Halpha':'H_p0_density', 'C III':'C_p2_density','C II':'C_p1_density',\n",
    "                 'C IV':'C_p3_density','O VI':'O_p5_density', 'Si III':'Si_p2_density', 'Si II':'Si_p1_density', 'Si IV':'Si_p3_density','Mg II':'Mg_p1_density'}\n",
    "    \n",
    "    label_dict = {'Lyalpha':r'Ly-$\\alpha$', 'Halpha':r'H$\\alpha$', 'C III':'C III','C II':'C II',\n",
    "                'C IV':'C IV','O VI':'O VI', 'Si III':'Si III'}\n",
    "\n",
    "    if unit_system  == 'default':\n",
    "        zlim_dict = {'Lyalpha':[1e-1,1e7], 'Halpha':[1e-1,1e6], 'C III':[1e-4,1e2],'C II':[1e-7,1e2],\n",
    "                 'C IV':[1e-2,1e4], 'O VI':[1e-2,1e4], 'Si III':[1e-1,1e4]}\n",
    "    elif unit_system == 'ALT':\n",
    "        zlim_dict = {'Lyalpha':[1e-22,1e-16], 'Halpha':[1e-22,1e-16], 'C III':[1e-26,1e-16],'C II':[1e-26,1e-16],\n",
    "                 'C IV':[1e-23,1e-16], 'O VI':[1e-23,1e-16], 'Si III':[1e-22,1e16]}\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "resolution_list = [2]#10,50,88]\n",
    "for reso in resolution_list:\n",
    "    load_and_calculate(snap, ions, unit_system='default', resolution=reso, filter_type = 'disk_cgm') #'default'or choose 'ALT' for erg unit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787d9bd-d973-428b-afbd-7b0177383da7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foggie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
